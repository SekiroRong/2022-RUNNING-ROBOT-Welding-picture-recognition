{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 引入\n",
    "* 在自动化焊接中，通常使用主动光源技术（线激光器），在焊接工件的表面形成激光线\n",
    "\n",
    "* 激光线在摄像机成像单元中的偏移数据反映了工件表面的形状信息，利用此信息可以完成焊缝的跟踪\n",
    "\n",
    "* 焊缝的跟踪通常要提取两个目标信息：\n",
    "\n",
    "    1. 激光线的提取\n",
    "\n",
    "    2. 在被提取激光线上定位感兴趣区域（焊缝区域）\n",
    "\n",
    "* 但在实际工况下，受焊接时弧光飞溅、光照变换的等影响，给这两个目标的完成造成了很大的难度\n",
    "\n",
    "* 所以本比赛寻求一种快速、精确的提取激光线与焊缝拐点位置的算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 参考资料\n",
    "* [国际自主机器人大赛官网](http://www.running-robot.net/)\n",
    "\n",
    "* [2022国际自主智能机器人大赛-焊接机器人焊接图片识别赛事](https://aistudio.baidu.com/aistudio/competition/detail/238)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 赛题介绍\n",
    "* 对焊接过程中激光传感器返回照片或视频进行分析，最终给出坡口位置的两个关键点\n",
    "\n",
    "* 需要模型能够对抗包括飞溅、焊渣遮蔽、不规则焊缝等干扰\n",
    "\n",
    "* 样例结果如下（蓝色矩形框为坡口位置，绿色曲线为激光线的 N 个关键点）：\n",
    "\n",
    "    ![](https://ai-studio-static-online.cdn.bcebos.com/bc2f19e2ea7e4adab7525e7c883687d396f765ff714748ce9e44cb391705b415)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 数据集\n",
    "* 本次比赛提供了 2875 张图像数据及其对应的标注文件\n",
    "\n",
    "* 图像均为 1920 x 1080 分辨率的 jpg 图像，标注文件为一个对应的 txt 文本文件\n",
    "\n",
    "* 标注文本中包含两部分的信息:\n",
    "\n",
    "    1. 激光线位置信息，在文本的第一行，本质是一维数组，数组长度1920，数据类型为整形，变化范围0-1079\n",
    "\n",
    "    2. 坡口位置信息，在文本的第二行，数据类型为整形，存储顺序 x1，y1，x2，y2\n",
    "\n",
    "* 标注文本中，行间使用分行符分隔，数字和数字之间以空格符分隔\n",
    "    \n",
    "* 数据样例如下：\n",
    "\n",
    "    |图像|可视化|\n",
    "    |:-:|:-:|\n",
    "    |![](https://ai-studio-static-online.cdn.bcebos.com/4df08243a42545d69ca9f9516b4690790d548c3912e048cb8dfc0f9516f5c7c5)|![](https://ai-studio-static-online.cdn.bcebos.com/bc2f19e2ea7e4adab7525e7c883687d396f765ff714748ce9e44cb391705b415)|\n",
    "\n",
    "    |激光线位置|坡口位置|\n",
    "    |:-:|:-:|\n",
    "    |`165 165 165 165 ... 206 206 206 206`|`422 180 1588 220`|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 算法目标\n",
    "* 对焊缝坡口的两个预测点相对于标签的偏移程度进行定量的打分，共有三个分数（总分，x轴预测得分，y轴预测得分）\n",
    "\n",
    "    1. x轴方向预测的数值相对于Label平均每偏移2个像素点，扣1分，满分100最低0分；\n",
    "\n",
    "    2. y轴方向的预测值相对于Label平均每偏移4个像素点扣1分，满分100最低0分；\n",
    "\n",
    "    3. 总分为上述x轴预测得分及y轴预测得分的平均分，最后排行榜结果会按照总分进行排序\n",
    "    \n",
    "    ![](http://bj.bcebos.com/v1/ai-studio-match/file/f412443875f54c3a8598f09ccf84d5ff2c4f7d46aa584d6cb9dc051410e536dc?authorization=bce-auth-v1%2F0ef6765c1e494918bc0d4c3ca3e5c6d1%2F2022-06-03T07%3A35%3A08Z%2F-1%2F%2Ffae5b80909454619fb760767cdcbbd940833a01f8e86db27608ec2a6680ebfce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 比赛基线\n",
    "## 6.1 基线说明\n",
    "* 本项目基于 PaddleX 开发，检测坡口位置可以使用简单的目标检测算法实现\n",
    "\n",
    "* PaddleX 内置了多种常见的深度学习机器视觉算法，如目标检测、图像分类、语义分割等\n",
    "\n",
    "* 使用 PaddleX 可以简单方便地完成比赛任务所需的模型训练和预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 安装依赖\n",
    "* 首先需要安装 PaddleX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T03:07:58.325680Z",
     "iopub.status.busy": "2022-06-18T03:07:58.325213Z",
     "iopub.status.idle": "2022-06-18T03:08:35.697731Z",
     "shell.execute_reply": "2022-06-18T03:08:35.697094Z",
     "shell.execute_reply.started": "2022-06-18T03:07:58.325651Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting paddlex\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ca/03/b401c6a34685aa698e7c2fbcfad029892cbfa4b562eaaa7722037fef86ed/paddlex-2.1.0-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: visualdl>=2.2.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (2.2.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (4.27.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (5.1.2)\n",
      "Requirement already satisfied: flask-cors in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (3.0.8)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (4.1.1.26)\n",
      "Collecting paddleslim==2.2.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/0b/dc/f46c4669d4cb35de23581a2380d55bf9d38bb6855aab1978fdb956d85da6/paddleslim-2.2.1-py3-none-any.whl (310 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.9/310.9 KB\u001b[0m \u001b[31m349.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (1.6.3)\n",
      "Collecting motmetrics\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/45/41/b019fe934eb811b9aba9b335f852305b804b9c66f098d7e35c2bdb09d1c8/motmetrics-1.2.5-py3-none-any.whl (161 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.1/161.1 KB\u001b[0m \u001b[31m150.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pycocotools\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/75/5c/ac61ea715d7a89ecc31c090753bde28810238225ca8b71778dfe3e6a68bc/pycocotools-2.0.4.tar.gz (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.6/106.6 KB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting lap\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/bf/64/d9fb6a75b15e783952b2fec6970f033462e67db32dc43dfbb404c14e91c2/lap-0.4.0.tar.gz (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: openpyxl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (3.0.5)\n",
      "Requirement already satisfied: chardet in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (3.0.4)\n",
      "Collecting shapely>=1.7.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d1/ec/3038263d69a0065d3ab6944ae839f5f00896efd29b13ae62d73c00345b95/Shapely-1.8.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (0.4.4)\n",
      "Collecting scikit-learn==0.23.2\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/f4/cb/64623369f348e9bfb29ff898a57ac7c91ed4921f228e9726546614d63ccb/scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleslim==2.2.1->paddlex) (2.2.3)\n",
      "Requirement already satisfied: pyzmq in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleslim==2.2.1->paddlex) (22.3.0)\n",
      "Requirement already satisfied: pillow in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleslim==2.2.1->paddlex) (8.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn==0.23.2->paddlex) (0.14.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn==0.23.2->paddlex) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn==0.23.2->paddlex) (1.19.5)\n",
      "Requirement already satisfied: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.2->paddlex) (1.0.0)\n",
      "Requirement already satisfied: shellcheck-py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.2->paddlex) (0.7.1.1)\n",
      "Requirement already satisfied: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.2->paddlex) (3.14.0)\n",
      "Requirement already satisfied: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.2->paddlex) (1.1.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.2->paddlex) (1.1.5)\n",
      "Requirement already satisfied: flake8>=3.7.9 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.2->paddlex) (4.0.1)\n",
      "Requirement already satisfied: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.2->paddlex) (1.21.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.2->paddlex) (1.16.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.2->paddlex) (2.24.0)\n",
      "Requirement already satisfied: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.2->paddlex) (0.8.53)\n",
      "Collecting xmltodict>=0.12.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/94/db/fd0326e331726f07ff7f40675cd86aa804bfd2e5016c727fa761c934990e/xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: jdcal in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from openpyxl->paddlex) (1.4.1)\n",
      "Requirement already satisfied: et-xmlfile in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from openpyxl->paddlex) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<4.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.2.2->paddlex) (4.2.0)\n",
      "Requirement already satisfied: pyflakes<2.5.0,>=2.4.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.2.2->paddlex) (2.4.0)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.2.2->paddlex) (0.6.1)\n",
      "Requirement already satisfied: pycodestyle<2.9.0,>=2.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.2.2->paddlex) (2.8.0)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.2.2->paddlex) (3.0.0)\n",
      "Requirement already satisfied: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.2.2->paddlex) (7.0)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.2.2->paddlex) (0.16.0)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.2.2->paddlex) (1.1.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.2.2->paddlex) (2019.3)\n",
      "Requirement already satisfied: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.2.2->paddlex) (2.8.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim==2.2.1->paddlex) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim==2.2.1->paddlex) (3.0.8)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim==2.2.1->paddlex) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim==2.2.1->paddlex) (0.10.0)\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.2.2->paddlex) (3.9.9)\n",
      "Requirement already satisfied: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.2.2->paddlex) (0.18.0)\n",
      "Requirement already satisfied: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.2.2->paddlex) (1.3.0)\n",
      "Requirement already satisfied: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.2.2->paddlex) (16.7.9)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.2.2->paddlex) (2.0.1)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.2.2->paddlex) (1.3.4)\n",
      "Requirement already satisfied: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.2.2->paddlex) (0.10.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.2.2->paddlex) (1.4.10)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.2.2->paddlex) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.2.2->paddlex) (1.25.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.2.2->paddlex) (2019.9.11)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata<4.3->flake8>=3.7.9->visualdl>=2.2.2->paddlex) (4.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata<4.3->flake8>=3.7.9->visualdl>=2.2.2->paddlex) (3.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0.0rc2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=1.1.1->visualdl>=2.2.2->paddlex) (2.0.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->paddleslim==2.2.1->paddlex) (56.2.0)\n",
      "Building wheels for collected packages: lap, pycocotools\n",
      "  Building wheel for lap (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lap: filename=lap-0.4.0-cp37-cp37m-linux_x86_64.whl size=1593869 sha256=1b3a0fe89f3197843d1df919beab75b96fba5d8eaa21fb274d99c90a94d0fd37\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/5c/d0/d2/e331d17a999666b1e2eb99743cfa1742629f9d26c55c657001\n",
      "  Building wheel for pycocotools (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.4-cp37-cp37m-linux_x86_64.whl size=273769 sha256=f51d73061e7e5b9c908ca248d28bbb4711e2c7944e3e66a41b99fd3f224ad537\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/c0/01/5f/670dfd20204fc9cc6bf843db4e014acb998f411922e3abc49f\n",
      "Successfully built lap pycocotools\n",
      "Installing collected packages: lap, xmltodict, shapely, scikit-learn, pycocotools, paddleslim, motmetrics, paddlex\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.24.2\n",
      "    Uninstalling scikit-learn-0.24.2:\n",
      "      Successfully uninstalled scikit-learn-0.24.2\n",
      "Successfully installed lap-0.4.0 motmetrics-1.2.5 paddleslim-2.2.1 paddlex-2.1.0 pycocotools-2.0.4 scikit-learn-0.23.2 shapely-1.8.2 xmltodict-0.13.0\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/opt/conda/envs/python35-paddle120-env/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install paddlex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 解压数据集\n",
    "* 比赛数据集已上传至 AIStudio 平台，并挂载在本项目中\n",
    "\n",
    "* 解压后即可直接使用该数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T07:00:51.702908Z",
     "iopub.status.busy": "2022-06-17T07:00:51.702439Z",
     "iopub.status.idle": "2022-06-17T07:01:00.569773Z",
     "shell.execute_reply": "2022-06-17T07:01:00.569100Z",
     "shell.execute_reply.started": "2022-06-17T07:00:51.702879Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data/data150501/测试集.zip\n",
      "  inflating: ./dataset/test/测试集/00001.jpg  \n",
      "  inflating: ./dataset/test/测试集/00002.jpg  \n",
      "  inflating: ./dataset/test/测试集/00003.jpg  \n",
      "  inflating: ./dataset/test/测试集/00004.jpg  \n",
      "  inflating: ./dataset/test/测试集/00005.jpg  \n",
      "  inflating: ./dataset/test/测试集/00006.jpg  \n",
      "  inflating: ./dataset/test/测试集/00007.jpg  \n",
      "  inflating: ./dataset/test/测试集/00008.jpg  \n",
      "  inflating: ./dataset/test/测试集/00009.jpg  \n",
      "  inflating: ./dataset/test/测试集/00010.jpg  \n",
      "  inflating: ./dataset/test/测试集/00011.jpg  \n",
      "  inflating: ./dataset/test/测试集/00012.jpg  \n",
      "  inflating: ./dataset/test/测试集/00013.jpg  \n",
      "  inflating: ./dataset/test/测试集/00014.jpg  \n",
      "  inflating: ./dataset/test/测试集/00015.jpg  \n",
      "  inflating: ./dataset/test/测试集/00016.jpg  \n",
      "  inflating: ./dataset/test/测试集/00017.jpg  \n",
      "  inflating: ./dataset/test/测试集/00018.jpg  \n",
      "  inflating: ./dataset/test/测试集/00019.jpg  \n",
      "  inflating: ./dataset/test/测试集/00020.jpg  \n",
      "  inflating: ./dataset/test/测试集/00021.jpg  \n",
      "  inflating: ./dataset/test/测试集/00022.jpg  \n",
      "  inflating: ./dataset/test/测试集/00023.jpg  \n",
      "  inflating: ./dataset/test/测试集/00024.jpg  \n",
      "  inflating: ./dataset/test/测试集/00025.jpg  \n",
      "  inflating: ./dataset/test/测试集/00026.jpg  \n",
      "  inflating: ./dataset/test/测试集/00027.jpg  \n",
      "  inflating: ./dataset/test/测试集/00028.jpg  \n",
      "  inflating: ./dataset/test/测试集/00029.jpg  \n",
      "  inflating: ./dataset/test/测试集/00030.jpg  \n",
      "  inflating: ./dataset/test/测试集/00031.jpg  \n",
      "  inflating: ./dataset/test/测试集/00032.jpg  \n",
      "  inflating: ./dataset/test/测试集/00033.jpg  \n",
      "  inflating: ./dataset/test/测试集/00034.jpg  \n",
      "  inflating: ./dataset/test/测试集/00035.jpg  \n",
      "  inflating: ./dataset/test/测试集/00036.jpg  \n",
      "  inflating: ./dataset/test/测试集/00037.jpg  \n",
      "  inflating: ./dataset/test/测试集/00038.jpg  \n",
      "  inflating: ./dataset/test/测试集/00039.jpg  \n",
      "  inflating: ./dataset/test/测试集/00040.jpg  \n",
      "  inflating: ./dataset/test/测试集/00041.jpg  \n",
      "  inflating: ./dataset/test/测试集/00042.jpg  \n",
      "  inflating: ./dataset/test/测试集/00043.jpg  \n",
      "  inflating: ./dataset/test/测试集/00044.jpg  \n",
      "  inflating: ./dataset/test/测试集/00045.jpg  \n",
      "  inflating: ./dataset/test/测试集/00046.jpg  \n",
      "  inflating: ./dataset/test/测试集/00047.jpg  \n",
      "  inflating: ./dataset/test/测试集/00048.jpg  \n",
      "  inflating: ./dataset/test/测试集/00049.jpg  \n",
      "  inflating: ./dataset/test/测试集/00050.jpg  \n",
      "  inflating: ./dataset/test/测试集/00051.jpg  \n",
      "  inflating: ./dataset/test/测试集/00052.jpg  \n",
      "  inflating: ./dataset/test/测试集/00053.jpg  \n",
      "  inflating: ./dataset/test/测试集/00054.jpg  \n",
      "  inflating: ./dataset/test/测试集/00055.jpg  \n",
      "  inflating: ./dataset/test/测试集/00056.jpg  \n",
      "  inflating: ./dataset/test/测试集/00057.jpg  \n",
      "  inflating: ./dataset/test/测试集/00058.jpg  \n",
      "  inflating: ./dataset/test/测试集/00059.jpg  \n",
      "  inflating: ./dataset/test/测试集/00060.jpg  \n",
      "  inflating: ./dataset/test/测试集/00061.jpg  \n",
      "  inflating: ./dataset/test/测试集/00062.jpg  \n",
      "  inflating: ./dataset/test/测试集/00063.jpg  \n",
      "  inflating: ./dataset/test/测试集/00064.jpg  \n",
      "  inflating: ./dataset/test/测试集/00065.jpg  \n",
      "  inflating: ./dataset/test/测试集/00066.jpg  \n",
      "  inflating: ./dataset/test/测试集/00067.jpg  \n",
      "  inflating: ./dataset/test/测试集/00068.jpg  \n",
      "  inflating: ./dataset/test/测试集/00069.jpg  \n",
      "  inflating: ./dataset/test/测试集/00070.jpg  \n",
      "  inflating: ./dataset/test/测试集/00071.jpg  \n",
      "  inflating: ./dataset/test/测试集/00072.jpg  \n",
      "  inflating: ./dataset/test/测试集/00073.jpg  \n",
      "  inflating: ./dataset/test/测试集/00074.jpg  \n",
      "  inflating: ./dataset/test/测试集/00075.jpg  \n",
      "  inflating: ./dataset/test/测试集/00076.jpg  \n",
      "  inflating: ./dataset/test/测试集/00077.jpg  \n",
      "  inflating: ./dataset/test/测试集/00078.jpg  \n",
      "  inflating: ./dataset/test/测试集/00079.jpg  \n",
      "  inflating: ./dataset/test/测试集/00080.jpg  \n",
      "  inflating: ./dataset/test/测试集/00081.jpg  \n",
      "  inflating: ./dataset/test/测试集/00082.jpg  \n",
      "  inflating: ./dataset/test/测试集/00083.jpg  \n",
      "  inflating: ./dataset/test/测试集/00084.jpg  \n",
      "  inflating: ./dataset/test/测试集/00085.jpg  \n",
      "  inflating: ./dataset/test/测试集/00086.jpg  \n",
      "  inflating: ./dataset/test/测试集/00087.jpg  \n",
      "  inflating: ./dataset/test/测试集/00088.jpg  \n",
      "  inflating: ./dataset/test/测试集/00089.jpg  \n",
      "  inflating: ./dataset/test/测试集/00090.jpg  \n",
      "  inflating: ./dataset/test/测试集/00091.jpg  \n",
      "  inflating: ./dataset/test/测试集/00092.jpg  \n",
      "  inflating: ./dataset/test/测试集/00093.jpg  \n",
      "  inflating: ./dataset/test/测试集/00094.jpg  \n",
      "  inflating: ./dataset/test/测试集/00095.jpg  \n",
      "  inflating: ./dataset/test/测试集/00096.jpg  \n",
      "  inflating: ./dataset/test/测试集/00097.jpg  \n",
      "  inflating: ./dataset/test/测试集/00098.jpg  \n",
      "  inflating: ./dataset/test/测试集/00099.jpg  \n"
     ]
    }
   ],
   "source": [
    "!mkdir ./dataset\n",
    "!mkdir ./dataset/img\n",
    "!tar -xf data/data150501/hegd.tar.gz -C ./dataset/img\n",
    "!unzip -O CP936 data/data150501/测试集.zip  -d ./dataset/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 数据处理\n",
    "* 将标注的坡口位置坐标点转换为 VOC 格式的目标检测数据，样例如下：\n",
    "\n",
    "    ```\n",
    "    842 456 1150 448 \n",
    "    ```\n",
    "\n",
    "    ```xml\n",
    "    <annotation>\n",
    "        <filename>2019-12-03_10-38-26_440_4400.jpg</filename>\n",
    "        <size>\n",
    "            <height>1080</height>\n",
    "            <width>1920</width>\n",
    "            <depth>3</depth>\n",
    "        </size>\n",
    "        <object>\n",
    "            <name>Groove</name>\n",
    "            <bndbox>\n",
    "                <xmin>842</xmin>\n",
    "                <ymin>448</ymin>\n",
    "                <xmax>1150</xmax>\n",
    "                <ymax>456</ymax>\n",
    "            </bndbox>\n",
    "        </object>\n",
    "    </annotation>\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-18T02:01:15.967787Z",
     "iopub.status.busy": "2022-06-18T02:01:15.967227Z",
     "iopub.status.idle": "2022-06-18T02:02:09.287957Z",
     "shell.execute_reply": "2022-06-18T02:02:09.287315Z",
     "shell.execute_reply.started": "2022-06-18T02:01:15.967748Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2875it [00:53, 54.24it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_datas(data_dir, endswith):\n",
    "    items = [os.path.join(data_dir, item) for item in os.listdir(data_dir)]\n",
    "    sub_dirs = [item for item in items if os.path.isdir(item)]\n",
    "    files = [item for item in items if item.endswith(endswith)]\n",
    "    for sub_dir in sub_dirs:\n",
    "        _files = get_datas(sub_dir, endswith)\n",
    "        files += _files\n",
    "    files.sort()\n",
    "    return files\n",
    "\n",
    "\n",
    "def makedirs(dir):\n",
    "    if not os.path.isdir(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "\n",
    "def vis_anno_label(jpg_files, txt_files, data_dir, xml_dir, list_dir, split_num):\n",
    "    data_list = []\n",
    "    for jpg_file, txt_file in tqdm(zip(jpg_files, txt_files)):\n",
    "        item_dir, item_file = os.path.split(jpg_file)\n",
    "        # complete = jpg_file.split('/')[4:]\n",
    "        # c = ''\n",
    "        # for i in complete:\n",
    "        #     c+=i\n",
    "        #     c+='/'\n",
    "        # c = c[:-1]\n",
    "        # # print(c)\n",
    "\n",
    "        img = cv2.imdecode(np.fromfile(jpg_file, dtype=np.uint8), -1)\n",
    "        with open(txt_file, 'r', encoding='UTF-8') as f:\n",
    "            line, position = [item.split(' ') for item in f.read().split('\\n')]\n",
    "\n",
    "        position = [int(item) for item in position if item]\n",
    "        x1, y1, x2, y2 = position\n",
    "\n",
    "        x1_l,x1_r = x1-10,x1+10\n",
    "        x2_l,x2_r = x2-10,x2+10\n",
    "        y1_l,y1_r = y1-10,y1+10\n",
    "        y2_l,y2_r = y2-10,y2+10\n",
    "        # x1, x2 = min(x1, x2), max(x1, x2)\n",
    "        # y1, y2 = min(y1, y2), max(y1, y2)\n",
    "\n",
    "        anno = f'''<annotation>\n",
    "    <filename>{item_file}</filename>\n",
    "    <size>\n",
    "        <height>{img.shape[0]}</height>\n",
    "        <width>{img.shape[1]}</width>\n",
    "        <depth>3</depth>\n",
    "    </size>\n",
    "    <object>\n",
    "        <name>Left</name>\n",
    "        <bndbox>\n",
    "            <xmin>{x1_l}</xmin>\n",
    "            <ymin>{y1_l}</ymin>\n",
    "            <xmax>{x1_r}</xmax>\n",
    "            <ymax>{y1_r}</ymax>\n",
    "        </bndbox>\n",
    "    </object>\n",
    "    <object>\n",
    "        <name>Right</name>\n",
    "        <bndbox>\n",
    "            <xmin>{x2_l}</xmin>\n",
    "            <ymin>{y2_l}</ymin>\n",
    "            <xmax>{x2_r}</xmax>\n",
    "            <ymax>{y2_r}</ymax>\n",
    "        </bndbox>\n",
    "    </object>\n",
    "</annotation>'''\n",
    "        makedirs(item_dir.replace(data_dir, xml_dir))\n",
    "        xml_file = jpg_file.replace(data_dir, xml_dir)[:-4]+'.xml'\n",
    "        with open(xml_file, 'w', encoding='UTF-8') as f:\n",
    "            f.write(anno)\n",
    "        \n",
    "        data_list.append(f'{jpg_file} {xml_file}\\n')\n",
    "    \n",
    "    random.shuffle(data_list)\n",
    "    with open(os.path.join(list_dir, 'train.txt'), 'w', encoding='UTF-8') as f:\n",
    "        for item in data_list[:split_num]:\n",
    "            f.write(item)\n",
    "    with open(os.path.join(list_dir, 'val.txt'), 'w', encoding='UTF-8') as f:\n",
    "        for item in data_list[split_num:]:\n",
    "            f.write(item)\n",
    "\n",
    "    with open(os.path.join(list_dir, 'trainval.txt'), 'w', encoding='UTF-8') as f:\n",
    "        for item in data_list:\n",
    "            f.write(item)\n",
    "    \n",
    "    with open(os.path.join(list_dir, 'label_list.txt'), 'w', encoding='UTF-8') as f:\n",
    "        f.write('Left\\n')\n",
    "        f.write('Right\\n')\n",
    "\n",
    "vis_anno_label(get_datas('./dataset/img', '.jpg'),\n",
    "               get_datas('./dataset/img', '.txt'), \n",
    "               './dataset/img', \n",
    "               './dataset/xml', \n",
    "               './dataset',\n",
    "               2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-17T07:38:26.892079Z",
     "iopub.status.busy": "2022-06-17T07:38:26.891166Z",
     "iopub.status.idle": "2022-06-17T07:47:12.688665Z",
     "shell.execute_reply": "2022-06-17T07:47:12.687798Z",
     "shell.execute_reply.started": "2022-06-17T07:38:26.892025Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-17 15:38:26 [INFO]\tStarting to read file list from dataset...\n",
      "2022-06-17 15:38:32 [INFO]\t2500 samples in file ./dataset/train.txt, including 2500 positive samples and 0 negative samples.\n",
      "creating index...\n",
      "index created!\n",
      "2022-06-17 15:38:32 [INFO]\tStarting to read file list from dataset...\n",
      "2022-06-17 15:38:32 [INFO]\t375 samples in file ./dataset/val.txt, including 375 positive samples and 0 negative samples.\n",
      "creating index...\n",
      "index created!\n",
      "2022-06-17 15:38:32 [INFO]\tLoading pretrained model from ./ckpt/pretrain/yolov3_mobilenet_v1_270e_coco.pdparams\n",
      "2022-06-17 15:38:33 [WARNING]\t[SKIP] Shape of pretrained params yolo_head.yolo_output.0.weight doesn't match.(Pretrained: [255, 1024, 1, 1], Actual: [18, 1024, 1, 1])\n",
      "2022-06-17 15:38:33 [WARNING]\t[SKIP] Shape of pretrained params yolo_head.yolo_output.0.bias doesn't match.(Pretrained: [255], Actual: [18])\n",
      "2022-06-17 15:38:33 [WARNING]\t[SKIP] Shape of pretrained params yolo_head.yolo_output.1.weight doesn't match.(Pretrained: [255, 512, 1, 1], Actual: [18, 512, 1, 1])\n",
      "2022-06-17 15:38:33 [WARNING]\t[SKIP] Shape of pretrained params yolo_head.yolo_output.1.bias doesn't match.(Pretrained: [255], Actual: [18])\n",
      "2022-06-17 15:38:33 [WARNING]\t[SKIP] Shape of pretrained params yolo_head.yolo_output.2.weight doesn't match.(Pretrained: [255, 256, 1, 1], Actual: [18, 256, 1, 1])\n",
      "2022-06-17 15:38:33 [WARNING]\t[SKIP] Shape of pretrained params yolo_head.yolo_output.2.bias doesn't match.(Pretrained: [255], Actual: [18])\n",
      "2022-06-17 15:38:33 [INFO]\tThere are 235/241 variables loaded into YOLOv3.\n",
      "2022-06-17 15:39:37 [INFO]\t[TRAIN] Epoch=1/20, Step=10/78, loss_xy=3.043134, loss_wh=4.050359, loss_obj=64.077850, loss_cls=0.466878, loss=71.638222, lr=0.000045, time_each_step=6.32s, eta=2:44:33\n",
      "2022-06-17 15:40:41 [INFO]\t[TRAIN] Epoch=1/20, Step=20/78, loss_xy=3.064740, loss_wh=3.220538, loss_obj=42.496613, loss_cls=0.441506, loss=49.223396, lr=0.000095, time_each_step=6.42s, eta=2:46:8\n",
      "2022-06-17 15:41:46 [INFO]\t[TRAIN] Epoch=1/20, Step=30/78, loss_xy=3.021867, loss_wh=2.343715, loss_obj=44.103928, loss_cls=0.525276, loss=49.994785, lr=0.000100, time_each_step=6.51s, eta=2:47:14\n",
      "2022-06-17 15:42:49 [INFO]\t[TRAIN] Epoch=1/20, Step=40/78, loss_xy=2.745592, loss_wh=2.296197, loss_obj=36.947464, loss_cls=0.557163, loss=42.546417, lr=0.000100, time_each_step=6.28s, eta=2:40:23\n",
      "2022-06-17 15:43:50 [INFO]\t[TRAIN] Epoch=1/20, Step=50/78, loss_xy=2.743057, loss_wh=3.090044, loss_obj=20.091715, loss_cls=0.779049, loss=26.703865, lr=0.000100, time_each_step=6.14s, eta=2:35:39\n",
      "2022-06-17 15:44:55 [INFO]\t[TRAIN] Epoch=1/20, Step=60/78, loss_xy=2.536731, loss_wh=1.936750, loss_obj=10.789360, loss_cls=0.639981, loss=15.902822, lr=0.000100, time_each_step=6.47s, eta=2:43:7\n",
      "2022-06-17 15:45:56 [INFO]\t[TRAIN] Epoch=1/20, Step=70/78, loss_xy=2.794503, loss_wh=2.603965, loss_obj=8.558702, loss_cls=0.533624, loss=14.490794, lr=0.000100, time_each_step=6.1s, eta=2:32:46\n",
      "2022-06-17 15:46:47 [INFO]\t[TRAIN] Epoch 1 finished, loss_xy=2.856907, loss_wh=2.9954274, loss_obj=349.08234, loss_cls=0.611737, loss=355.54642 .\n",
      "2022-06-17 15:46:47 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-06-17 15:46:47 [INFO]\tStart to evaluate(total_samples=375, total_steps=375)...\n",
      "2022-06-17 15:46:57 [INFO]\tAccumulating evaluatation results...\n",
      "2022-06-17 15:46:57 [INFO]\t[EVAL] Finished, Epoch=1, bbox_map=0.127368 .\n",
      "2022-06-17 15:46:58 [INFO]\tModel saved in ./ckpt/best_model.\n",
      "2022-06-17 15:46:58 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_1, bbox_map=0.1273682534628244\n",
      "2022-06-17 15:47:00 [INFO]\tModel saved in ./ckpt/epoch_1.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_228/3756357996.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0msave_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./ckpt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0muse_vdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mlog_interval_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m )\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/models/detector.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_epochs, train_dataset, train_batch_size, eval_dataset, optimizer, save_interval_epochs, log_interval_steps, save_dir, pretrain_weights, learning_rate, warmup_steps, warmup_start_lr, lr_decay_epochs, lr_decay_gamma, metric, use_ema, early_stop, early_stop_patience, use_vdl, resume_checkpoint)\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0mearly_stop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0mearly_stop_patience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stop_patience\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             use_vdl=use_vdl)\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     def quant_aware_train(self,\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/models/base.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(self, num_epochs, train_dataset, train_batch_size, eval_dataset, save_interval_epochs, log_interval_steps, save_dir, ema, early_stop, early_stop_patience, use_vdl)\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mstep_time_tic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnranks\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mddp_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m_in_legacy_dygraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_next_var_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_restore_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure_infos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# in static mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import paddlex as pdx\n",
    "from paddlex import transforms as T\n",
    "\n",
    "\n",
    "train_transforms = T.Compose([\n",
    "    # T.RandomCrop(),\n",
    "    # T.RandomHorizontalFlip(),\n",
    "    T.Resize(\n",
    "        target_size=[288, 512],\n",
    "        interp='LINEAR'\n",
    "    ),\n",
    "    T.RandomDistort(),\n",
    "    T.RandomBlur(prob=0.2),\n",
    "    T.MixupImage(alpha=1.5, beta=1.5, mixup_epoch=10),\n",
    "    T.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "# 验证集数据增强\n",
    "eval_transforms = T.Compose([\n",
    "    T.Resize(\n",
    "        target_size=[288, 512], interp='LINEAR'),\n",
    "    T.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# 训练集\n",
    "train_dataset = pdx.datasets.VOCDetection(\n",
    "    data_dir='./',\n",
    "    file_list='./dataset/train.txt',\n",
    "    label_list='./dataset/label_list.txt',\n",
    "    transforms=train_transforms,\n",
    "    num_workers=4,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# 验证集\n",
    "eval_dataset = pdx.datasets.VOCDetection(\n",
    "    data_dir='./',\n",
    "    file_list='./dataset/val.txt',\n",
    "    label_list='./dataset/label_list.txt',\n",
    "    transforms=eval_transforms,\n",
    "    num_workers=4,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 检测模型\n",
    "num_classes = len(train_dataset.labels)\n",
    "# print(num_classes)\n",
    "# model = pdx.det.FasterRCNN(num_classes=2, backbone='ResNet101_vd', aspect_ratios=[1.0], anchor_sizes=[[30], [60]], keep_top_k=20,test_pre_nms_top_n=20, test_post_nms_top_n=20)\n",
    "# model = pdx.det.YOLOv3(num_classes=num_classes)\n",
    "model = pdx.det.PPYOLOv2(num_classes=num_classes, backbone='ResNet101_vd_dcn')\n",
    "\n",
    "# 模型训练\n",
    "model.train(\n",
    "    num_epochs=20,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    train_batch_size=16,\n",
    "    pretrain_weights='COCO',\n",
    "    learning_rate=0.0001,\n",
    "    warmup_steps=200,\n",
    "    warmup_start_lr=0.0,\n",
    "    save_interval_epochs=10,\n",
    "    lr_decay_epochs=[25, 28],\n",
    "    save_dir='./ckpt',\n",
    "    use_vdl=False,\n",
    "    log_interval_steps=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 模型预测\n",
    "* 测试集的结果需保存为 txt 格式，文件命名为 test-1.txt，然后直接进行压缩，最终的提交结果必须是 test-1.zip\n",
    "\n",
    "* 提交的结果文件需要参照下列的要求：\n",
    "\n",
    "    1. 测试集图片信息，在文本的第 0 列，一共 99 张图片\n",
    " \n",
    "    2. 坡口位置信息，在文本的第 1-4 列，数据类型为整形，存储顺序 x1，y1，x2，y2\n",
    "\n",
    "\n",
    "* 提交文件格式样例如下：\n",
    "\n",
    "    ```\n",
    "    00001.jpg 1083 329 1557 349\n",
    "    00002.jpg 1087 413 1370 428\n",
    "    00003.jpg 1129 409 1417 428\n",
    "    00004.jpg 1070 415 1371 419\n",
    "    ...\n",
    "    00096.jpg 1060 408 1390 430\n",
    "    00097.jpg 1112 413 1436 426\n",
    "    00098.jpg 1097 413 1451 427\n",
    "    00099.jpg 1131 414 1421 426\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T03:19:22.594685Z",
     "iopub.status.busy": "2022-06-18T03:19:22.593903Z",
     "iopub.status.idle": "2022-06-18T03:19:32.702035Z",
     "shell.execute_reply": "2022-06-18T03:19:32.701005Z",
     "shell.execute_reply.started": "2022-06-18T03:19:22.594648Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "(Fatal) Operator gaussian_random raises an paddle::memory::allocation::BadAlloc exception.\nThe exception content is\n:ResourceExhaustedError: \n\nOut of memory error on GPU 0. Cannot allocate 2.250000MB memory on GPU 0, 31.744873GB memory has been allocated and available memory is only 3.750000MB.\n\nPlease check whether there is any other process using GPU 0.\n1. If yes, please stop them, or start PaddlePaddle on another GPU.\n2. If no, please decrease the batch size of your model. \nIf the above ways do not solve the out of memory problem, you can try to use CUDA managed memory. The command is `export FLAGS_use_cuda_managed_memory=false`.\n (at /paddle/paddle/fluid/memory/allocation/cuda_allocator.cc:87)\n. (at /paddle/paddle/fluid/imperative/tracer.cc:307)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_165/3854000503.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msubmit_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./test-1.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtest_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/models/load_model.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(model_dir, **params)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         model = getattr(paddlex.cv.models, model_info['Model'])(\n\u001b[0;32m---> 86\u001b[0;31m             **model_info['_init_params'])\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwith_net\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             if status == 'Pruned' or osp.exists(\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/models/detector.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_classes, backbone, anchors, anchor_masks, use_iou_aware, use_spp, use_drop_block, scale_x_y, ignore_threshold, label_smooth, use_iou_loss, use_matrix_nms, nms_score_threshold, nms_topk, nms_keep_topk, nms_iou_threshold, **params)\u001b[0m\n\u001b[1;32m   1819\u001b[0m                     \u001b[0mfreeze_at\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1820\u001b[0m                     \u001b[0mfreeze_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1821\u001b[0;31m                     norm_decay=0.)\n\u001b[0m\u001b[1;32m   1822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1823\u001b[0m             neck = ppdet.modeling.PPYOLOPAN(\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/models/detector.py\u001b[0m in \u001b[0;36m_get_backbone\u001b[0;34m(self, backbone_name, **params)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_backbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackbone_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mbackbone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mppdet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackbone_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbackbone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/ppdet/modeling/backbones/resnet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, depth, ch_in, variant, lr_mult_list, groups, base_width, norm_type, norm_decay, freeze_norm, freeze_at, return_idx, dcn_v2_stages, num_stages, std_senet)\u001b[0m\n\u001b[1;32m    557\u001b[0m                     \u001b[0mfreeze_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfreeze_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m                     \u001b[0mdcn_v2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdcn_v2_stages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m                     std_senet=std_senet))\n\u001b[0m\u001b[1;32m    560\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mch_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_out_channels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/ppdet/modeling/backbones/resnet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, block, ch_in, ch_out, count, name_adapter, stage_num, variant, groups, base_width, lr, norm_type, norm_decay, freeze_norm, dcn_v2, std_senet)\u001b[0m\n\u001b[1;32m    417\u001b[0m                     \u001b[0mfreeze_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfreeze_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                     \u001b[0mdcn_v2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdcn_v2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m                     std_senet=std_senet))\n\u001b[0m\u001b[1;32m    420\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/ppdet/modeling/backbones/resnet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ch_in, ch_out, stride, shortcut, variant, groups, base_width, lr, norm_type, norm_decay, freeze_norm, dcn_v2, std_senet)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mfreeze_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfreeze_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             dcn_v2=dcn_v2)\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         self.branch2c = ConvNormLayer(\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/ppdet/modeling/backbones/resnet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ch_in, ch_out, filter_size, stride, groups, act, norm_type, norm_decay, freeze_norm, lr, dcn_v2)\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mweight_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mParamAttr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 bias_attr=False)\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffset_channel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfilter_size\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, padding_mode, weight_attr, bias_attr, data_format)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0mweight_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_attr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m             \u001b[0mbias_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias_attr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             data_format=data_format)\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, transposed, dims, stride, padding, padding_mode, output_padding, dilation, groups, weight_attr, bias_attr, data_format)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilter_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mattr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param_attr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             default_initializer=_get_default_param_initializer())\n\u001b[0m\u001b[1;32m    137\u001b[0m         self.bias = self.create_parameter(\n\u001b[1;32m    138\u001b[0m             attr=self._bias_attr, shape=[self._out_channels], is_bias=True)\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36mcreate_parameter\u001b[0;34m(self, shape, attr, dtype, is_bias, default_initializer)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mtemp_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         return self._helper.create_parameter(temp_attr, shape, dtype, is_bias,\n\u001b[0;32m--> 424\u001b[0;31m                                              default_initializer)\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     @deprecated(\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layer_helper_base.py\u001b[0m in \u001b[0;36mcreate_parameter\u001b[0;34m(self, attr, shape, dtype, is_bias, default_initializer, stop_gradient, type)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0mstop_gradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop_gradient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                 **attr._to_kwargs(with_initializer=True))\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             self.startup_program.global_block().create_parameter(\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\u001b[0m in \u001b[0;36mcreate_parameter\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3570\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3571\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3572\u001b[0;31m                 \u001b[0minitializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3573\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/initializer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, var, block)\u001b[0m\n\u001b[1;32m    365\u001b[0m             out_var = _C_ops.gaussian_random(\n\u001b[1;32m    366\u001b[0m                 \u001b[0;34m'shape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dtype'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m                 'std', self._std_dev, 'seed', self._seed, 'use_mkldnn', False)\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mVarDesc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVarType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFP16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVarDesc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVarType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBF16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: (Fatal) Operator gaussian_random raises an paddle::memory::allocation::BadAlloc exception.\nThe exception content is\n:ResourceExhaustedError: \n\nOut of memory error on GPU 0. Cannot allocate 2.250000MB memory on GPU 0, 31.744873GB memory has been allocated and available memory is only 3.750000MB.\n\nPlease check whether there is any other process using GPU 0.\n1. If yes, please stop them, or start PaddlePaddle on another GPU.\n2. If no, please decrease the batch size of your model. \nIf the above ways do not solve the out of memory problem, you can try to use CUDA managed memory. The command is `export FLAGS_use_cuda_managed_memory=false`.\n (at /paddle/paddle/fluid/memory/allocation/cuda_allocator.cc:87)\n. (at /paddle/paddle/fluid/imperative/tracer.cc:307)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import paddlex as pdx\n",
    "\n",
    "model_path = './ckpt/best_model'\n",
    "test_dir = './dataset/test/测试集'\n",
    "submit_file = './test-1.txt'\n",
    "\n",
    "model = pdx.load_model(model_path)\n",
    "\n",
    "test_imgs = os.listdir(test_dir)\n",
    "# print(test_imgs)\n",
    "test_files = [os.path.join(test_dir, img_file) for img_file in test_imgs]\n",
    "\n",
    "# print(test_files)\n",
    "\n",
    "# results = model.predict(test_files)\n",
    "# print(results)\n",
    "results = []\n",
    "for ti in test_files:\n",
    "    # print(ti)\n",
    "    results.append(model.predict(ti))\n",
    "\n",
    "texts = []\n",
    "for result, img in zip(results, test_imgs):\n",
    "    # print(result[0])\n",
    "    # print(result)\n",
    "    # print(result[3])\n",
    "    left_score=0\n",
    "    right_score=0\n",
    "    for r in result:\n",
    "        if r['category_id']==0:\n",
    "            if r['score']>left_score:\n",
    "                left_score=r['score']\n",
    "                x1,y1=round(r['bbox'][0]+0.5*r['bbox'][2]),round(r['bbox'][1]+0.5*r['bbox'][3])\n",
    "        if r['category_id']==1:\n",
    "            if r['score']>right_score:\n",
    "                right_score=r['score']\n",
    "                x2,y2=round(r['bbox'][0]+0.5*r['bbox'][2]),round(r['bbox'][1]+0.5*r['bbox'][3])\n",
    "    # print(len(result))\n",
    "    # print(result)\n",
    "    # x1, y1, w, h = result[0]['bbox']\n",
    "    # x2, y2 = x1+w, y1+h\n",
    "    x1,x2 = min(x1,x2),max(x1,x2)\n",
    "    y1,y2 = min(y1,y2),max(y1,y2)\n",
    "    bbox = [int(item) for item in [x1, y1, x2, y2]]\n",
    "    texts.append('%s %d %d %d %d\\n' % (img, *bbox))\n",
    "texts.sort()\n",
    "\n",
    "with open(submit_file, 'w', encoding='UTF-8') as f:\n",
    "    for line in texts:\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.7 结果可视化\n",
    "* 使用 PaddleX 可视化 API 对测试集数据检测结果进行可视化，样例如下：\n",
    "\n",
    "    ![](https://ai-studio-static-online.cdn.bcebos.com/de6e440e51e44034b9ae0d112de6cfd575079ebdde6f4f38bbf55c028d5e37cc)\n",
    "    \n",
    "    ![](https://ai-studio-static-online.cdn.bcebos.com/3a59f390ea724da2bd23c0e0b1fa443bd8e59fe75dd74bf990985fee502fca5d)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-17T07:10:56.861257Z",
     "iopub.status.idle": "2022-06-17T07:10:56.861816Z",
     "shell.execute_reply": "2022-06-17T07:10:56.861681Z",
     "shell.execute_reply.started": "2022-06-17T07:10:56.861665Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for img, result in zip(test_files, results):\n",
    "    pdx.det.visualize(img, result, threshold=0.5, save_dir='./vis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.8 结果提交\n",
    "* 根据提交要求，使用如下命令对结果文件进行压缩\n",
    "\n",
    "* 前往比赛页面中的 [提交结果](https://aistudio.baidu.com/aistudio/competition/detail/238/0/submit-result) 选项卡中上传压缩文件进行提交\n",
    "\n",
    "    ![](https://ai-studio-static-online.cdn.bcebos.com/0896fed473204837b99190d377237edc0aa5589e7311452b9d0bc0d557010a55)\n",
    "\n",
    "* 提交之后，等待系统自动完成评分过程，就可以在下方查看提交的结果的得分详情了\n",
    "\n",
    "    ![](https://ai-studio-static-online.cdn.bcebos.com/8633e7cc08f546b79d919ff1e31415a29facbad30bfe47f69066af8149cf4e03)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-17T07:10:56.862855Z",
     "iopub.status.idle": "2022-06-17T07:10:56.863274Z",
     "shell.execute_reply": "2022-06-17T07:10:56.863101Z",
     "shell.execute_reply.started": "2022-06-17T07:10:56.863080Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!zip test-1.zip test-1.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 优化建议\n",
    "* 数据层面：\n",
    "\n",
    "    1. 额外数据：利用额外的激光线位置信息辅助坡口位置定位\n",
    "\n",
    "    2. 数据增广：尝试使用各种数据增广的方式\n",
    "\n",
    "* 模型层面：\n",
    "\n",
    "    1. 超参数调节：学习率 / 训练轮次 等等\n",
    "    \n",
    "    2. 更换模型：更换其他目标检测模型算法\n",
    "    \n",
    "    3. 预测逻辑：优化预测逻辑，提高准确度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. 尾巴\n",
    "* 现在越来越多工具的出现使得搭建一个基线项目变得很轻松\n",
    "\n",
    "* 能够极大的助力比赛打榜的效率,可以腾出更多时间和精力\n",
    "\n",
    "* 去专注于研发和尝试新的算法模型，新的数据处理方案等等\n",
    "\n",
    "* 总结一句话就是：善用工具能够事半功倍\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
